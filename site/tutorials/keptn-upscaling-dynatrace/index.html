
<!doctype html>

<html>
<head>
  <meta name="viewport" content="width=device-width, minimum-scale=1.0, initial-scale=1.0, user-scalable=yes">
  <meta name="theme-color" content="#4F7DC9">
  <meta charset="UTF-8">
  <title>Automated Upscaling with Dynatrace</title>
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Source+Code+Pro:400|Roboto:400,300,400italic,500,700|Roboto+Mono">
  <link rel="stylesheet" href="//fonts.googleapis.com/icon?family=Material+Icons">
  <link rel="stylesheet" href="https://storage.googleapis.com/codelab-elements/codelab-elements.css">
  <style>
    .success {
      color: #1e8e3e;
    }
    .error {
      color: red;
    }
  </style>
</head>
<body>
  <google-codelab-analytics gaid="UA-133584243-1"></google-codelab-analytics>
  <google-codelab codelab-gaid=""
                  id="keptn-upscaling-dynatrace"
                  title="Automated Upscaling with Dynatrace"
                  environment="web"
                  feedback-link="https://github.com/keptn/tutorials/tree/master/site/tutorials">
    
      <google-codelab-step label="Welcome" duration="2">
        <p>In this tutorial, you will learn how to use the capabilities of Keptn to provide self-healing for an application without modifying code. The following tutorial will scale up the pods of an application if the application undergoes heavy CPU saturation.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Prerequisites" duration="0">
        <p>Please make sure you already have a Keptn installatin running. Take a look at <a href="../../?cat=installation" target="_blank">these tutorials</a> to get started in case you don&#39;t have your Keptn set up yet.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Create your first project" duration="5">
        <p>A project in Keptn is the logical unit that can hold multiple (micro)services. Therefore, it is the starting point for each Keptn installation.</p>
<p>To get all files you need for this tutorial, please clone the example repo to your local machine.</p>
<pre><code>git clone --branch release-0.6.2 https://github.com/keptn/examples.git --single-branch

cd examples/onboarding-carts
</code></pre>
<p>Create a new project for your services using the <code>keptn create project</code> command. In this example, the project is called <em>sockshop</em>. Before executing the following command, make sure you are in the <code>examples/onboarding-carts</code> folder.</p>
<p><strong>Recommended:</strong> Create a new project with Git upstream:</p>
<p>To configure a Git upstream for this tutorial, the Git user (<code>--git-user</code>), an access token (<code>--git-token</code>), and the remote URL (<code>--git-remote-url</code>) are required. If a requirement is not met, go to <a href="https://keptn.sh/docs/0.6.0/manage/project/#select-git-based-upstream" target="_blank">the Keptn documentation</a> where instructions for GitHub, GitLab, and Bitbucket are provided.</p>
<pre><code>keptn create project sockshop --shipyard=./shipyard.yaml --git-user=GIT_USER --git-token=GIT_TOKEN --git-remote-url=GIT_REMOTE_URL
</code></pre>
<p><strong>Alternatively:</strong> If you don&#39;t want to use a Git upstream, you can create a new project without it but please note that this is not the recommended way:</p>
<pre><code>keptn create project sockshop --shipyard=./shipyard.yaml
</code></pre>
<p>For creating the project, the tutorial relies on a <code>shipyard.yaml</code> file as shown below:</p>
<pre><code>stages:
  - name: &#34;dev&#34;
    deployment_strategy: &#34;direct&#34;
    test_strategy: &#34;functional&#34;
  - name: &#34;staging&#34;
    deployment_strategy: &#34;blue_green_service&#34;
    test_strategy: &#34;performance&#34;
  - name: &#34;production&#34;
    deployment_strategy: &#34;blue_green_service&#34;
    remediation_strategy: &#34;automated&#34;
</code></pre>
<p>This shipyard contains three stages: dev, staging, and production. This results in the three Kubernetes namespaces: sockshop-dev, sockshop-staging, and sockshop-production.</p>
<ul>
<li><strong>dev</strong> will have a direct (big bang) deployment strategy and functional tests are executed</li>
<li><strong>staging</strong> will have a blue/green deployment strategy and performance tests are executed</li>
<li><strong>production</strong> will have a blue/green deployment strategy without any further testing. The configured remediation strategy is used for self-healing in production.</li>
</ul>
<aside class="special"><p>To learn more about a <em>shipyard</em> file, please take a look at the <a href="https://github.com/keptn/spec/blob/master/shipyard.md" target="_blank">Shipyard specification</a>.</p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Onboard first microservice" duration="5">
        <p>After creating the project, services can be onboarded to our project.</p>
<ol type="1">
<li>Onboard the <strong>carts</strong> service using the <a href="https://keptn.sh/docs/0.6.0/reference/cli/commands/keptn_onboard_service/" target="_blank">keptn onboard service</a> command:<pre><code>keptn onboard service carts --project=sockshop --chart=./carts
</code></pre>
</li>
<li>After onboarding the service, tests (i.e., functional- and performance tests) need to be added as basis for quality gates in the different stages:<ul>
<li>Functional tests for <em>dev</em> stage:<pre><code>keptn add-resource --project=sockshop --stage=dev --service=carts --resource=jmeter/basiccheck.jmx --resourceUri=jmeter/basiccheck.jmx
</code></pre>
</li>
<li>Performance tests for <em>staging</em> stage:<pre><code>keptn add-resource --project=sockshop --stage=staging --service=carts --resource=jmeter/load.jmx --resourceUri=jmeter/load.jmx
</code></pre>
</li>
</ul>
<strong>Note:</strong> You can adapt the tests in <code>basiccheck.jmx</code> as well as <code>load.jmx</code> for your service. However, you must not rename the files because there is a hardcoded dependency on these file names in the current implementation of Keptn&#39;s jmeter-service.</li>
</ol>
<p>Since the carts service requires a mongodb database, a second service needs to be onboarded.</p>
<ul>
<li>Onboard the <strong>carts-db</strong> service using the <a href="https://keptn.sh/docs/0.6.0/reference/cli/commands/keptn_onboard_service/" target="_blank">keptn onboard service</a> command. The <code>--deployment-strategy</code> flag specifies that for this service a <em>direct</em> deployment strategy in all stages should be used regardless of the deployment strategy specified in the shipyard. Thus, the database is not blue/green deployed.<pre><code>keptn onboard service carts-db --project=sockshop --chart=./carts-db --deployment-strategy=direct
</code></pre>
</li>
</ul>


      </google-codelab-step>
    
      <google-codelab-step label="Deploy first build with Keptn" duration="5">
        <p>After onboarding the services, a built artifact of each service can be deployed.</p>
<ol type="1">
<li>Deploy the carts-db service by executing the <a href="https://keptn.sh/docs/0.6.0/reference/cli/commands/keptn_send_event_new-artifact/" target="_blank">keptn send event new-artifact</a> command:<pre><code>keptn send event new-artifact --project=sockshop --service=carts-db --image=docker.io/mongo --tag=4.2.2
</code></pre>
</li>
<li>Deploy the carts service by specifying the built artifact, which is stored on DockerHub and tagged with version 0.11.1:<pre><code>keptn send event new-artifact --project=sockshop --service=carts --image=docker.io/keptnexamples/carts --tag=0.11.1
</code></pre>
</li>
<li>Go to Keptn&#39;s Bridge and check which events have already been generated. You can access it by a port-forward from your local machine to the Kubernetes cluster:<pre><code>kubectl port-forward svc/bridge -n keptn 9000:8080
</code></pre>
</li>
<li>The Keptn&#39;s Bridge is then available on <a href="http://localhost:9000" target="_blank">http://localhost:9000</a>.<br>It shows all deployments that have been triggered. On the left-hand side, you can see the deployment start events (i.e., so-called <code>Configuration change</code> events). During a deployment, Keptn generates events for controlling the deployment process. These events will also show up in Keptn&#39;s Bridge. Please note that if events are sent at the same time, their order in the Keptn&#39;s Bridge might be arbitrary since they are sorted on the granularity of one second.<img alt="Keptn's Bridge" src="img/5a1640c50f69de79.png"></li>
<li><strong>Optional:</strong> Verify the pods that should have been created for services carts and carts-db:<pre><code>kubectl get pods --all-namespaces | grep carts
</code></pre>
<pre><code>sockshop-dev          carts-77dfdc664b-25b74                            1/1     Running     0          10m
sockshop-dev          carts-db-54d9b6775-lmhf6                          1/1     Running     0          13m
sockshop-production   carts-db-54d9b6775-4hlwn                          2/2     Running     0          12m
sockshop-production   carts-primary-79bcc7c99f-bwdhg                    2/2     Running     0          2m15s
sockshop-staging      carts-db-54d9b6775-rm8rw                          2/2     Running     0          12m
sockshop-staging      carts-primary-79bcc7c99f-mbbgq                    2/2     Running     0          7m24s
</code></pre>
</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="View carts service" duration="2">
        <ol type="1">
<li>Get the URL for your carts service with the following commands in the respective namespaces:<pre><code>echo http://carts.sockshop-dev.$(kubectl get cm keptn-domain -n keptn -o=jsonpath=&#39;{.data.app_domain}&#39;)
</code></pre>
<pre><code>echo http://carts.sockshop-staging.$(kubectl get cm keptn-domain -n keptn -o=jsonpath=&#39;{.data.app_domain}&#39;)
</code></pre>
<pre><code>echo http://carts.sockshop-production.$(kubectl get cm keptn-domain -n keptn -o=jsonpath=&#39;{.data.app_domain}&#39;)
</code></pre>
</li>
<li>Navigate to the URLs to inspect the carts service. In the production namespace, you should receive an output similar to this:</li>
</ol>
<p class="image-container"><img alt="carts in production" src="img/da8218ae54b69582.png"></p>


      </google-codelab-step>
    
      <google-codelab-step label="Generate traffic" duration="2">
        <p>Now that the service is running in all three stages, let us generate some traffic so we have some data we can base the evaluation on.</p>
<p>Change the directory to <code>examples/load-generation/cartsloadgen</code>. If you are still in the onboarding-carts directory, use the following command or change it accordingly:</p>
<pre><code>cd ../load-generation/cartsloadgen
</code></pre>
<p>Now let us deploy a pod that will generate some traffic for all three stages of our demo environment.</p>
<pre><code>kubectl apply -f deploy/cartsloadgen-base.yaml 
</code></pre>
<p>The output will look similar to this.</p>
<pre><code>namespace/loadgen created
deployment.extensions/cartsloadgen created
</code></pre>
<p>Optionally, you can verify that the load generator has been started.</p>
<pre><code>kubectl get pods -n loadgen

NAME                            READY   STATUS    RESTARTS   AGE
cartsloadgen-5dc47c85cf-kqggb   1/1     Running   0          117s
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Setup Dynatrace" duration="7">
        <p>For enabling the Keptn Quality Gates, we are going to use Dynatrace as the data provider. Therefore, we are going to setup Dynatrace in our Kubernetes cluster to have our sample application monitored and we can use the monitoring data for both the basis for evaluating quality gates as well as a trigger to start self-healing.</p>
<aside class="special"><p>You have to bring your own Dynatrace tenant</p>
</aside>
<p>If you don&#39;t have a Dynatrace tenant yet, sign up for a <a href="https://www.dynatrace.com/trial/" target="_blank">free trial</a> or a <a href="https://www.dynatrace.com/developer/" target="_blank">developer account</a>.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Gather Dynatrace tokens" duration="6">
        <ol type="1">
<li>Create a Dynatrace API TokenLog in to your Dynatrace tenant and go to <strong>Settings &gt; Integration &gt; Dynatrace API</strong>. Then, create a new API token with the following permissions:<ul>
<li>Access problem and event feed, metrics and topology</li>
<li>Access logs</li>
<li>Read configuration</li>
<li>Write configuration</li>
<li>Capture request data</li>
</ul>
Take a look at this screenshot to double check the right token permissions for you.<img alt="Dynatrace API Token" src="img/2c13d90861689a.png"></li>
<li>Create a Dynatrace PaaS TokenIn your Dynatrace tenant, go to <strong>Settings &gt; Integration &gt; Platform as a Service</strong>, and create a new PaaS Token.</li>
<li>Store your credentials in a Kubernetes secret by executing the following command. The <code>DT_TENANT</code> has to be set according to the appropriate pattern:<ul>
<li>Dynatrace SaaS tenant (this format is most likely for you): <code>{your-environment-id}.live.dynatrace.com</code></li>
<li>Dynatrace-managed tenant: <code>{your-domain}/e/{your-environment-id}</code></li>
</ul>
If running on a Unix/Linux based system, you can use variables for ease of use. Naturally, it is also fine to just replace the values in the <code>kubectl</code> command itself.<pre><code>DT_TENANT=yourtenant.live.dynatrace.com
DT_API_TOKEN=yourAPItoken
DT_PAAS_TOKEN=yourPAAStoken
</code></pre>
If you used the variables, the next command can be copied and pasted without modifications. If you have not set the variable, please make sure to set the right values in the next command.<pre><code>kubectl -n keptn create secret generic dynatrace --from-literal=&#34;DT_TENANT=$DT_TENANT&#34; --from-literal=&#34;DT_API_TOKEN=$DT_API_TOKEN&#34;  --from-literal=&#34;DT_PAAS_TOKEN=$DT_PAAS_TOKEN&#34;
</code></pre>
</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Install Dynatrace integration" duration="5">
        <ol type="1">
<li>The Dynatrace integration into Keptn is handled by the <em>dynatrace-service</em>. To install the <em>dynatrace-service</em>, execute:<pre><code>kubectl apply -f https://raw.githubusercontent.com/keptn-contrib/dynatrace-service/0.7.1/deploy/manifests/dynatrace-service/dynatrace-service.yaml
</code></pre>
</li>
<li>When the service is deployed, use the following command to install Dynatrace on your cluster. If Dynatrace is already deployed, the current deployment of Dynatrace will not be modified.<pre><code>keptn configure monitoring dynatrace
</code></pre>
</li>
</ol>
<p><strong>Verify Dynatrace configuration</strong></p>
<p>Since Keptn has configured your Dynatrace tenant, let us take a look what has be done for you:</p>
<ul>
<li><em>Tagging rules:</em> When you navigate to <strong>Settings &gt; Tags &gt; Automatically applied tags</strong> in your Dynatrace tenant, you will find following tagging rules:<ul>
<li>keptn_deployment</li>
<li>keptn_project</li>
<li>keptn_service</li>
<li>keptn_stage<br><br></li>
</ul>
This means that Dynatrace will automatically apply tags to your onboarded services.</li>
<li><em>Problem notification:</em> A problem notification has been set up to inform Keptn of any problems with your services to allow auto-remediation. You can check the problem notification by navigating to <strong>Settings &gt; Integration &gt; Problem notifications</strong> and you will find a <strong>keptn remediation</strong> problem notification.</li>
<li><em>Alerting profile:</em> An alerting profile with all problems set to <em>0 minutes</em> (immediate) is created. You can review this profile by navigating to <strong>Settings &gt; Alerting &gt; Alerting profiles</strong>.</li>
<li><em>Dashboard and Mangement zone:</em> When creating a new Keptn project or executing the <a href="https://keptn.sh/docs/0.6.0/reference/cli/commands/keptn_configure_monitoring/" target="_blank">keptn configure monitoring</a> command for a particular project (see Note 1), a dashboard and management zone will be generated reflecting the environment as specified in the shipyard file.</li>
</ul>
<aside class="warning"><p>If the nodes in your cluster run on <em>Container-Optimized OS (cos)</em> (default for GKE), the Dynatrace OneAgent might not work properly, the next steps are necessary.</p>
</aside>
<p>Follow the next steps only if your Dynatrace OneAgent does not work properly.</p>
<ol type="1">
<li>To check if the OneAgent does not work properly, the output of <code>kubectl get pods -n dynatrace</code> might look as follows:<pre><code>NAME                                           READY   STATUS             RESTARTS   AGE
dynatrace-oneagent-operator-7f477bf78d-dgwb6   1/1     Running            0          8m21s
oneagent-b22m4                                 0/1     Error              6          8m15s
oneagent-k7jn6                                 0/1     CrashLoopBackOff   6          8m15s
</code></pre>
</li>
<li>This means that after the initial setup you need to edit the OneAgent custom resource in the Dynatrace namespace and add the following entry to the env section:<pre><code>env:
- name: ONEAGENT_ENABLE_VOLUME_STORAGE
  value: &#34;true&#34;
</code></pre>
</li>
<li>To edit the OneAgent custom resource:<pre><code>kubectl edit oneagent -n dynatrace
</code></pre>
</li>
</ol>
<p>At the end of your installation, please verify that all Dynatrace resources are in a Ready and Running status by executing <code>kubectl get pods -n dynatrace</code>:</p>
<pre><code>NAME                                           READY   STATUS       RESTARTS   AGE
dynatrace-oneagent-operator-7f477bf78d-dgwb6   1/1     Running      0          8m21s
oneagent-b22m4                                 1/1     Running      0          8m21s
oneagent-k7jn6                                 1/1     Running      0          8m21s
</code></pre>


      </google-codelab-step>
    
      <google-codelab-step label="Configure Dynatrace with Keptn" duration="4">
        <p>To inform Keptn about any issues in a production environment, monitoring has to be set up correctly. The Keptn CLI helps with the automated setup and configuration of Dynatrace as the monitoring solution running in the Kubernetes cluster.</p>
<p>To add these files to Keptn and to automatically configure Dynatrace, execute the following commands:</p>
<ol type="1">
<li>Make sure you are in the correct folder of your examples directory:<pre><code>cd examples/onboarding-carts
</code></pre>
</li>
<li>Configure remediation actions for up-scaling based on Dynatrace alerts:<pre><code>keptn add-resource --project=sockshop --stage=production --service=carts --resource=remediation.yaml --resourceUri=remediation.yaml
</code></pre>
This is how the file looks that we are going to add here:<pre><code>remediations:
- name: response_time_p90
  actions:
  - action: scaling
    value: +1
- name: Response time degradation
  actions:
  - action: scaling
    value: +1
</code></pre>
</li>
<li>Configure Dynatrace with the Keptn CLI (we have done this earlier already but we make sure that our project is configured correctly):<pre><code>keptn configure monitoring dynatrace --project=sockshop
</code></pre>
</li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Configure your Dynatrace tenant" duration="5">
        <p>Configure Dynatrace problem detection with a fixed threshold: For the sake of this demo, we will configure Dynatrace to detect problems based on fixed thresholds rather than automatically.</p>
<p>Log in to your Dynatrace tenant and go to <strong>Settings &gt; Anomaly Detection &gt; Services</strong>.</p>
<p>Within this menu, select the option <strong>Detect response time degradations using fixed thresholds</strong>, set the limit to <strong>1000ms</strong>, and select <strong>Medium</strong> for the sensitivity as shown below.</p>
<p class="image-container"><img alt="anomaly detection" src="img/ed36ecb82a65b1c8.png"></p>
<aside class="special"><p>You can also configure those fixed thresholds per service instead of globally.</p>
</aside>


      </google-codelab-step>
    
      <google-codelab-step label="Run the experiment" duration="7">
        <p>To simulate user traffic that is causing an unhealthy behavior in the carts service, please execute the following script. This will add special items into the shopping cart that cause some extensive calculation.</p>
<ol type="1">
<li>Move to the correct folder for the load generation scripts:<pre><code>cd ../load-generation/cartsloadgen/deploy
</code></pre>
</li>
<li>Start the load generation script:<pre><code>kubectl apply -f cartsloadgen-faulty.yaml
</code></pre>
</li>
<li>Start the load generation script depending on your OS (replace _OS_ with linux, mac, or win):<pre><code>./loadgenerator-_OS_ &#34;http://carts.sockshop-production.$(kubectl get cm keptn-domain -n keptn -o=jsonpath=&#39;{.data.app_domain}&#39;)&#34; cpu
</code></pre>
</li>
<li><strong>Optional:</strong> Verify the load in DynatraceIn your Dynatrace Tenant, inspect the <em>Response Time</em> chart of the correlating service entity of the carts microservice. <em>Hint:</em> You can find the service<br>in Dynatrace easier by selecting the management zone <strong>Keptn: sockshop production</strong>:<img alt="services" src="img/7797ed336a124785.png"><img alt="response time" src="img/53fefe55c50338e9.png"></li>
</ol>
<p>As you can see in the time series chart, the load generation script causes a significant increase in the response time.</p>


      </google-codelab-step>
    
      <google-codelab-step label="Watch self-healing in action" duration="10">
        <p>After approximately 10-15 minutes, Dynatrace will send out a problem notification because of the response time degradation.</p>
<p>After receiving the problem notification, the <em>dynatrace-service</em> will translate it into a Keptn CloudEvent. This event will eventually be received by the <em>remediation-service</em> that will look for a remediation action specified for this type of problem and, if found, execute it.</p>
<p>In this tutorial, the number of pods will be increased to remediate the issue of the response time increase.</p>
<ol type="1">
<li>Check the executed remediation actions by executing:<pre><code>kubectl get deployments -n sockshop-production
</code></pre>
You can see that the <code>carts-primary</code> deployment is now served by two pods:<pre><code>NAME             DESIRED   CURRENT   UP-TO-DATE   AVAILABLE   AGE
carts-db         1         1         1            1           37m
carts-primary    2         2         2            2           32m
</code></pre>
</li>
<li>Besides, you should see an additional pod running when you execute:<pre><code>kubectl get pods -n sockshop-production
</code></pre>
<pre><code>NAME                              READY   STATUS    RESTARTS   AGE
carts-db-57cd95557b-r6cg8         1/1     Running   0          38m
carts-primary-7c96d87df9-75pg7    2/2     Running   0          33m
carts-primary-7c96d87df9-78fh2    2/2     Running   0          5m
</code></pre>
</li>
<li>To get an overview of the actions that got triggered by the response time SLO violation, you can use the Keptn&#39;s Bridge. You can access it by a port-forward from your local machine to the Kubernetes cluster:<pre><code>kubectl port-forward svc/bridge -n keptn 9000:8080
</code></pre>
Now access the bridge from your browser on http://localhost:9000.In this example, the bridge shows that the remediation service triggered an update of the configuration of the carts service by increasing the number of replicas to 2. When the additional replica was available, the wait-service waited for 10 minutes for the remediation action to take effect. Afterwards, an evaluation by the lighthouse-service was triggered to check if the remediation action resolved the problem. In this case, increasing the number of replicas achieved the desired effect since the evaluation of the service level objectives has been successful.<img alt="bridge" src="img/937ffb041f71eb34.png"></li>
<li>Furthermore, you can see how the response time of the service decreased by viewing the time series chart in Dynatrace:As previously, go to the response time chart of the <em>ItemsController</em> service. Here you will see that the additional instance has helped to bring down the response time.<br>Eventually, the problem that has been detected earlier will be closed automatically.<img alt="problem closed" src="img/1fdd302e45ad1e3e.png"></li>
</ol>


      </google-codelab-step>
    
      <google-codelab-step label="Finish" duration="0">
        <p>You have successfully walked through the example to scale up your application based on high CPU consumption detected by Dynatrace.</p>
<h2 class="checklist" is-upgraded>What we&#39;ve covered</h2>
<ul class="checklist">
<li>Setting up auto-remediation with a <code>remediation.yaml</code> file<pre><code>remediations:
- name: response_time_p90
actions:
- action: scaling
  value: +1
- name: Response time degradation
actions:
- action: scaling
  value: +1
</code></pre>
</li>
<li>Execute an experiment to see self-healing in action<br><img alt="response time" src="img/53fefe55c50338e9.png"></li>
<li>Verified that Keptn executed the remediation action<br><img alt="bridge" src="img/937ffb041f71eb34.png"></li>
</ul>


      </google-codelab-step>
    
  </google-codelab>

  <script src="https://storage.googleapis.com/codelab-elements/native-shim.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/custom-elements.min.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/prettify.js"></script>
  <script src="https://storage.googleapis.com/codelab-elements/codelab-elements.js"></script>

</body>
</html>
